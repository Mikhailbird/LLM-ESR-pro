{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1852f56",
   "metadata": {},
   "source": [
    "##### Heterogeneous graph construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d9a83d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import GATConv, RGCNConv\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import copy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94420e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/beauty/handled\"\n",
    "id_map = json.load(open(os.path.join(data_dir, \"id_map.json\")))\n",
    "item2attr = json.load(open(os.path.join(data_dir, \"item2attributes.json\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26037e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "def build_prompt_graph(id_map_path, item2attr_path):\n",
    "    \"\"\"\n",
    "    Constructs a heterogeneous item-attribute graph from item2id and item2attributes JSON files.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load mappings\n",
    "    id_map = json.load(open(id_map_path))[\"item2id\"]  # maps ASIN to integer ID\n",
    "    item2attr = json.load(open(item2attr_path))       # maps ASIN to attribute list\n",
    "\n",
    "    # Keep only items present in both files\n",
    "    valid_raw_ids = set(item2attr.keys()) & set(id_map.keys())\n",
    "    print(f\"# of matched items: {len(valid_raw_ids)}\")\n",
    "\n",
    "    # Map valid item raw IDs to their dense integer ID\n",
    "    mapped_attr = {int(id_map[raw_id]): item2attr[raw_id] for raw_id in valid_raw_ids}\n",
    "    max_item_id = max(mapped_attr.keys())\n",
    "\n",
    "    # Create graph\n",
    "    graph = HeteroData()\n",
    "    graph['item'].num_nodes = max_item_id + 1\n",
    "\n",
    "    attr2id = {}\n",
    "    attr_cnt = 0\n",
    "\n",
    "    # Edge containers\n",
    "    edge_index_dict = {\n",
    "        ('item', 'has_brand', 'attribute'): [[], []],\n",
    "        ('attribute', 'rev_has_brand', 'item'): [[], []],\n",
    "        ('item', 'has_category', 'attribute'): [[], []],\n",
    "        ('attribute', 'rev_has_category', 'item'): [[], []],\n",
    "        ('item', 'has_price', 'attribute'): [[], []],\n",
    "        ('attribute', 'rev_has_price', 'item'): [[], []],\n",
    "    }\n",
    "\n",
    "    # Build edge indices\n",
    "    for item_id, attrs in mapped_attr.items():\n",
    "        for attr in attrs:\n",
    "            if ':' not in attr:\n",
    "                continue  # skip attributes without prefix (e.g. generic)\n",
    "            prefix, value = attr.split(':', 1)\n",
    "\n",
    "            if attr not in attr2id:\n",
    "                attr2id[attr] = attr_cnt\n",
    "                attr_cnt += 1\n",
    "\n",
    "            aid = attr2id[attr]\n",
    "\n",
    "            if prefix == 'brand':\n",
    "                edge_index_dict[('item', 'has_brand', 'attribute')][0].append(item_id)\n",
    "                edge_index_dict[('item', 'has_brand', 'attribute')][1].append(aid)\n",
    "                edge_index_dict[('attribute', 'rev_has_brand', 'item')][0].append(aid)\n",
    "                edge_index_dict[('attribute', 'rev_has_brand', 'item')][1].append(item_id)\n",
    "\n",
    "            elif prefix in ['cat', 'category']:\n",
    "                edge_index_dict[('item', 'has_category', 'attribute')][0].append(item_id)\n",
    "                edge_index_dict[('item', 'has_category', 'attribute')][1].append(aid)\n",
    "                edge_index_dict[('attribute', 'rev_has_category', 'item')][0].append(aid)\n",
    "                edge_index_dict[('attribute', 'rev_has_category', 'item')][1].append(item_id)\n",
    "\n",
    "            elif prefix == 'price':\n",
    "                edge_index_dict[('item', 'has_price', 'attribute')][0].append(item_id)\n",
    "                edge_index_dict[('item', 'has_price', 'attribute')][1].append(aid)\n",
    "                edge_index_dict[('attribute', 'rev_has_price', 'item')][0].append(aid)\n",
    "                edge_index_dict[('attribute', 'rev_has_price', 'item')][1].append(item_id)\n",
    "\n",
    "    # Assign number of attribute nodes\n",
    "    graph['attribute'].num_nodes = attr_cnt\n",
    "\n",
    "    # Convert edge lists to PyTorch tensors\n",
    "    for rel, (src, dst) in edge_index_dict.items():\n",
    "        graph[rel].edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
    "\n",
    "    # Print basic stats\n",
    "    print(f\"Item nodes: {graph['item'].num_nodes}\")\n",
    "    print(f\"Attribute nodes: {graph['attribute'].num_nodes}\")\n",
    "    for rel in graph.edge_index_dict:\n",
    "        print(f\"{rel}: {graph[rel].edge_index.shape[1]} edges\")\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2209058a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of matched items: 57289\n",
      "Item nodes: 57290\n",
      "Attribute nodes: 6474\n",
      "('item', 'has_brand', 'attribute'): 41458 edges\n",
      "('attribute', 'rev_has_brand', 'item'): 41458 edges\n",
      "('item', 'has_category', 'attribute'): 57289 edges\n",
      "('attribute', 'rev_has_category', 'item'): 57289 edges\n",
      "('item', 'has_price', 'attribute'): 50299 edges\n",
      "('attribute', 'rev_has_price', 'item'): 50299 edges\n",
      "Item nodes: 57290\n",
      "Attribute nodes: 6474\n",
      "('item', 'has_brand', 'attribute'): 41458 edges\n",
      "('attribute', 'rev_has_brand', 'item'): 41458 edges\n",
      "('item', 'has_category', 'attribute'): 57289 edges\n",
      "('attribute', 'rev_has_category', 'item'): 57289 edges\n",
      "('item', 'has_price', 'attribute'): 50299 edges\n",
      "('attribute', 'rev_has_price', 'item'): 50299 edges\n"
     ]
    }
   ],
   "source": [
    "graph = build_prompt_graph(data_dir+\"/\"+\"id_map.json\", data_dir+\"/\"+\"item2attributes_flat.json\")\n",
    "print(f\"Item nodes: {graph['item'].num_nodes}\")\n",
    "print(f\"Attribute nodes: {graph['attribute'].num_nodes}\")\n",
    "\n",
    "for rel in graph.edge_index_dict:\n",
    "    print(f\"{rel}: {graph[rel].edge_index.shape[1]} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fed1986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 64\n",
    "graph['item'].x = torch.randn(graph['item'].num_nodes, hidden_dim)\n",
    "graph['attribute'].x = torch.randn(graph['attribute'].num_nodes, hidden_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e22b2b",
   "metadata": {},
   "source": [
    "##### prompt GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfc82db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv, HeteroConv\n",
    "import torch.nn as nn\n",
    "\n",
    "class PromptGAT(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.convs1 = HeteroConv({\n",
    "            ('item', 'has_brand', 'attribute'): GATConv(hidden_dim, hidden_dim, add_self_loops=False),\n",
    "            ('attribute', 'rev_has_brand', 'item'): GATConv(hidden_dim, hidden_dim, add_self_loops=False),\n",
    "            ('item', 'has_category', 'attribute'): GATConv(hidden_dim, hidden_dim, add_self_loops=False),\n",
    "            ('attribute', 'rev_has_category', 'item'): GATConv(hidden_dim, hidden_dim, add_self_loops=False),\n",
    "            ('item', 'has_price', 'attribute'): GATConv(hidden_dim, hidden_dim, add_self_loops=False),\n",
    "            ('attribute', 'rev_has_price', 'item'): GATConv(hidden_dim, hidden_dim, add_self_loops=False),\n",
    "        }, aggr='sum')\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        self.convs2 = HeteroConv({\n",
    "            ('item', 'has_brand', 'attribute'): GATConv(hidden_dim, hidden_dim, add_self_loops=False),\n",
    "            ('attribute', 'rev_has_brand', 'item'): GATConv(hidden_dim, hidden_dim, add_self_loops=False),\n",
    "            ('item', 'has_category', 'attribute'): GATConv(hidden_dim, hidden_dim, add_self_loops=False),\n",
    "            ('attribute', 'rev_has_category', 'item'): GATConv(hidden_dim, hidden_dim, add_self_loops=False),\n",
    "            ('item', 'has_price', 'attribute'): GATConv(hidden_dim, hidden_dim, add_self_loops=False),\n",
    "            ('attribute', 'rev_has_price', 'item'): GATConv(hidden_dim, hidden_dim, add_self_loops=False),\n",
    "        }, aggr='sum')\n",
    "\n",
    "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict = self.convs1(x_dict, edge_index_dict)\n",
    "        x_dict = {k: self.norm1(F.relu(F.dropout(v, p=self.dropout, training=self.training))) for k, v in x_dict.items()}\n",
    "\n",
    "        x_dict = self.convs2(x_dict, edge_index_dict)\n",
    "        x_dict = {k: self.norm2(F.relu(F.dropout(v, p=self.dropout, training=self.training))) for k, v in x_dict.items()}\n",
    "\n",
    "        return x_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50c6aa5",
   "metadata": {},
   "source": [
    "##### get GNN embedding and use HeteroConv to deal with each type of relationship separately"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19beaa0",
   "metadata": {},
   "source": [
    "#### Apply Graph Contrastive Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4599c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start contrastive training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 3/3 [00:10<00:00,  3.45s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from tqdm import trange\n",
    "import pickle\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "graph = graph.to(device)\n",
    "model = PromptGAT(hidden_dim=64, dropout=0.2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# contrastive loss\n",
    "def contrastive_loss(item_emb, attr_emb, edge_index, num_attr, num_neg=10):\n",
    "    loss = 0.0\n",
    "    total = edge_index.shape[1]\n",
    "\n",
    "    for i in range(total):\n",
    "        item_idx = edge_index[0, i]\n",
    "        attr_pos_idx = edge_index[1, i]\n",
    "\n",
    "        z_i = item_emb[item_idx]          # (64,)\n",
    "        z_pos = attr_emb[attr_pos_idx]    # (64,)\n",
    "\n",
    "        neg_indices = torch.randint(0, num_attr, (num_neg,), device=item_emb.device)\n",
    "        z_neg = attr_emb[neg_indices]     # (num_neg, 64)\n",
    "\n",
    "        pos_score = torch.exp(F.cosine_similarity(z_i, z_pos, dim=0) / 0.1)  # temperature = 0.1\n",
    "        neg_score = torch.exp(torch.cosine_similarity(z_i.unsqueeze(0), z_neg, dim=1) / 0.1).sum()\n",
    "\n",
    "        loss += -torch.log(pos_score / (pos_score + neg_score + 1e-8))\n",
    "\n",
    "    return loss / total\n",
    "\n",
    "# train\n",
    "print(\"Start contrastive training...\")\n",
    "for epoch in tqdm(trange(100)):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    out_dict = model(graph.x_dict, graph.edge_index_dict)\n",
    "    item_emb = out_dict['item']\n",
    "    attr_emb = out_dict['attribute']\n",
    "\n",
    "    loss = 0\n",
    "    for rel in tqdm(['has_brand', 'has_category', 'has_price']):\n",
    "        \n",
    "        edge_index = graph[('item', rel, 'attribute')].edge_index\n",
    "        if edge_index.size(1) == 0:\n",
    "            continue\n",
    "        loss += contrastive_loss(item_emb, attr_emb, edge_index, graph['attribute'].num_nodes)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}: loss = {loss.item():.4f}\")\n",
    "\n",
    "# save\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out_dict = model(graph.x_dict, graph.edge_index_dict)\n",
    "    item_emb = out_dict['item'].cpu().numpy()\n",
    "\n",
    "with open(\"data/beauty/handled/gnn_item_emb.pkl\", \"wb\") as f:\n",
    "    pickle.dump(item_emb, f)\n",
    "\n",
    "print(\"GNN embedding saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab466f2",
   "metadata": {},
   "source": [
    "##### Future: AutoEncoder / SimCLR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7903e75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### work to be discussed #####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3a7f4a",
   "metadata": {},
   "source": [
    "##### some check for dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7705a7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57289, 1536)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"data/beauty/handled/itm_emb_np.pkl\",\"rb\") as f:\n",
    "    data_llm = pickle.load(f)\n",
    "data_llm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b94e9be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57289, 64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"data/beauty/handled/pca64_itm_emb_np.pkl\",\"rb\") as f:\n",
    "    data_pca = pickle.load(f)\n",
    "data_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e49b21f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57289, 64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"graph_data/gnn_item_emb.pkl\",\"rb\") as f:\n",
    "    data_gnn = pickle.load(f)\n",
    "data_gnn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2860656",
   "metadata": {},
   "source": [
    "##### concatenate collaborative view and gnn view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44bdd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_shape: (57289, 64)\n",
      "gnn_shape: (57289, 64)\n",
      "the dimension of fused embedding is (57289, 128)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load LLM PCA64 embedding\n",
    "with open(\"data/beauty/handled/pca64_itm_emb_np.pkl\", \"rb\") as f:\n",
    "    col_emb = pickle.load(f)  # shape: [num_items, 64]\n",
    "\n",
    "# Load GNN output\n",
    "with open(\"graph_data/gnn_itm_emb.pkl\", \"rb\") as f:\n",
    "    gnn_emb = pickle.load(f)  # shape: [num_items, 64]\n",
    "print(f\"col_shape: {col_emb.shape}\")\n",
    "print(f\"gnn_shape: {gnn_emb.shape}\")\n",
    "assert col_emb.shape[0] == gnn_emb.shape[0], \"Mismatch in item count\"\n",
    "\n",
    "# Concatenate: [LLM || GNN]\n",
    "fused_emb = np.concatenate([col_emb, gnn_emb], axis=1)  # shape: [num_items, 128]\n",
    "\n",
    "# Save fused embedding\n",
    "with open(\"graph_data/fused_pca64_itm_emb_np.pkl\", \"wb\") as f:\n",
    "    pickle.dump(fused_emb, f)\n",
    "\n",
    "\n",
    "with open(\"graph_data/fused_pca64_itm_emb_np.pkl\", \"rb\") as f:\n",
    "    fused_data = pickle.load(f)\n",
    "print(f\"the dimension of fused embedding is {fused_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7df38b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collobrative embedding item [0]: \n",
      " [ 0.06981667  0.14442578  0.0535023  -0.08414154  0.09463756 -0.03626085\n",
      " -0.03035027  0.00369254  0.00710129 -0.06218467  0.01594733 -0.05304417\n",
      "  0.08057744  0.00208946 -0.03156804  0.00423898 -0.02121462  0.01415135\n",
      "  0.08333678  0.0289374  -0.00776773  0.02657525 -0.01858179 -0.00593037\n",
      "  0.00067705 -0.00235615 -0.02065355 -0.03762729 -0.03606503 -0.03609613\n",
      " -0.00611113 -0.00296575 -0.01485604  0.07745654 -0.01674157  0.01220707\n",
      " -0.01177268  0.03651463  0.03259253 -0.03159697 -0.00206229  0.00366125\n",
      " -0.03166092  0.01766294  0.02784831 -0.00016647 -0.03964143 -0.00597224\n",
      "  0.05646616  0.01536507  0.01450725  0.01923479  0.00642199  0.0380005\n",
      " -0.00581556 -0.01339675 -0.02487696  0.02866836  0.02915967  0.03548247\n",
      "  0.02508577  0.04911524  0.03779834  0.03975626]\n",
      "gnn embedding item [0]: \n",
      " [-4.9440339e-03 -2.4531004e-03 -7.0671751e-03  7.7628912e-03\n",
      "  1.8639162e-03 -6.2251380e-03  6.0575115e-03 -3.1166142e-03\n",
      " -6.3754283e-03 -1.4521150e-03 -1.7033037e-03  4.8350194e-03\n",
      "  6.1176303e-03  2.3945901e-03  1.9392933e-03  7.7304238e-04\n",
      "  6.8994152e-04 -8.2814367e-03  4.8537632e-03  6.5763714e-04\n",
      " -7.1846880e-03 -4.4974787e-03  6.9011436e-03  4.8030154e-03\n",
      "  2.3196086e-03  1.5673274e-03 -3.9302730e-03 -3.3251958e-03\n",
      "  1.7881846e-03  2.0156631e-03  5.3487443e-03 -3.7951896e-03\n",
      " -7.5474399e-04  2.1716978e-03  1.9095022e-03 -5.5027916e-03\n",
      " -1.7185587e-03 -5.1754252e-03 -7.4740611e-03  2.1224734e-03\n",
      "  5.8918656e-03 -3.0657374e-03 -1.5401914e-03  2.1433805e-03\n",
      "  6.6229906e-03 -6.6800785e-05 -1.1610994e-03  3.3525433e-04\n",
      "  1.8630455e-03 -1.3686832e-03 -4.9826559e-03  5.5056168e-03\n",
      " -9.0106996e-04  1.2802125e-03  4.0389557e-05 -2.5528525e-03\n",
      " -6.6562109e-03  6.5875496e-04 -4.1675302e-03 -1.7496101e-03\n",
      " -4.4190343e-03  3.3809973e-03 -4.2266138e-03  7.3808441e-03]\n"
     ]
    }
   ],
   "source": [
    "print(f\"collobrative embedding item [0]: \\n {col_emb[0]}\")\n",
    "print(f\"gnn embedding item [0]: \\n {gnn_emb[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2368bce4",
   "metadata": {},
   "source": [
    "##### Map GNN embedding to the same scale as pca embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ff0bb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mean = col_emb.mean()\n",
    "target_std = col_emb.std()\n",
    "\n",
    "gnn_item_emb = (gnn_emb - gnn_emb.mean()) / gnn_emb.std()\n",
    "gnn_item_emb = gnn_item_emb * target_std + target_mean\n",
    "\n",
    "with open(\"graph_data/gnn_itm_emb_np.pkl\", \"wb\") as f:\n",
    "    pickle.dump(gnn_item_emb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d05b0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collobrative embedding item [0]: \n",
      " [ 0.06981667  0.14442578  0.0535023  -0.08414154  0.09463756 -0.03626085\n",
      " -0.03035027  0.00369254  0.00710129 -0.06218467  0.01594733 -0.05304417\n",
      "  0.08057744  0.00208946 -0.03156804  0.00423898 -0.02121462  0.01415135\n",
      "  0.08333678  0.0289374  -0.00776773  0.02657525 -0.01858179 -0.00593037\n",
      "  0.00067705 -0.00235615 -0.02065355 -0.03762729 -0.03606503 -0.03609613\n",
      " -0.00611113 -0.00296575 -0.01485604  0.07745654 -0.01674157  0.01220707\n",
      " -0.01177268  0.03651463  0.03259253 -0.03159697 -0.00206229  0.00366125\n",
      " -0.03166092  0.01766294  0.02784831 -0.00016647 -0.03964143 -0.00597224\n",
      "  0.05646616  0.01536507  0.01450725  0.01923479  0.00642199  0.0380005\n",
      " -0.00581556 -0.01339675 -0.02487696  0.02866836  0.02915967  0.03548247\n",
      "  0.02508577  0.04911524  0.03779834  0.03975626]\n",
      "gnn embedding item [0]: \n",
      " [-0.04472134 -0.02084337 -0.06507367  0.07708662  0.02053933 -0.05700194\n",
      "  0.06073893 -0.02720378 -0.05844261 -0.01124798 -0.01365586  0.04902019\n",
      "  0.06131523  0.02562635  0.0212619   0.01008227  0.00928567 -0.07671352\n",
      "  0.04919986  0.008976   -0.06620014 -0.04044068  0.06882595  0.0487134\n",
      "  0.02490758  0.01769625 -0.03500348 -0.02920324  0.01981338  0.02199397\n",
      "  0.05394473 -0.03370858 -0.00456301  0.02348971  0.02097632 -0.05007756\n",
      " -0.01380209 -0.04693944 -0.06897406  0.02301785  0.05915106 -0.02671608\n",
      " -0.01209227  0.02321826  0.06615959  0.00203158 -0.00845832  0.00588566\n",
      "  0.02053099 -0.0104482  -0.04509157  0.05544849 -0.00596569  0.01494398\n",
      "  0.0030591  -0.02179959 -0.06113419  0.00898672 -0.03727781 -0.01409975\n",
      " -0.03968872  0.035082   -0.03784418  0.07342433]\n"
     ]
    }
   ],
   "source": [
    "with open(\"graph_data/gnn_itm_emb_np.pkl\", \"rb\") as f:\n",
    "    gnn_emb = pickle.load(f)\n",
    "\n",
    "print(f\"collobrative embedding item [0]: \\n {col_emb[0]}\")\n",
    "print(f\"gnn embedding item [0]: \\n {gnn_emb[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
